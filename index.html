<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8"> <!-- 声明文档的字符集 -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
    <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- 设置网页视口的元数据标签 -->
    <title>OpenGS-SLAM</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet"> <!-- 表示被链接的文件是一个样式表文件 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <!-- 内容划分元素 -->
    <div class="jumbotron text-center mt-0"> <!--jumbotron类可用于创建具有特殊样式的大型容器，text-center类用于居中文本，而mt-0类用于删除顶部的外边距-->
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2> OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian
            Splatting </h2>
            <h2> for Object-Level Scene Understanding </h2>
            <h4 style="color:#5a6268;">Current state: Continue Updating(last time:2024.9.15)</h4>
            <hr>
            <h6> 
                <a target="_blank">Dianyi Yang</a><sup>1</sup>,
                <a target="_blank">Yu Gao</a><sup>1</sup>, 
                <a target="_blank">Xihan Wang</a><sup>1</sup>, 
                <a target="_blank">Yufeng Yue</a><sup>1</sup>, 
                <a target="_blank">Yi Yang</a><sup>1†</sup>, 
                <a target="_blank">Mengyin Fu</a><sup>1</sup>
            <p>
                <sup>1</sup>Beijing Institute of Technology &nbsp;&nbsp; 
                <sup>†</sup>Corresponding Author &nbsp;&nbsp; 
              </p>
            <div class="row justify-content-center">
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2309.07846" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div> -->
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://young-bit.github.io/opengs-github.github.io/" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code(Comming Soon)</a> </p>
              </div>
              <!-- <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://drive.google.com/drive/folders/16cdEC9WmDmiAp3oPmVwwhl_is6qUDh0K" role="button"  target="_blank">
                  <i class="fa fa-database"></i> Dataset</a> </p>
              </div> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
          <p class="text-justify">Recent advancements in 3D Gaussian Splatting have significantly improved the efficiency and quality of dense semantic SLAM. However, previous methods are generally constrained by limited-category pre-trained classifiers and implicit semantic representation, which hinder their performance in open-set scenarios and restrict 3D object-level scene understanding. To address these issues, we propose OpenGS-SLAM, an innovative framework that utilizes 3D Gaussian representation to perform dense semantic SLAM in open-set environments. Our system integrates explicit semantic labels derived from 2D foundational models into the 3D Gaussian framework, facilitating robust 3D object-level scene understanding. We introduce Gaussian Voting Splatting to enable fast 2D label map rendering and scene updating. Additionally, we propose a Confidence-based 2D Label Consensus method to ensure consistent labeling across multiple views. Furthermore, we employ a Segmentation Counter Pruning strategy to improve the accuracy of semantic scene representation. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method in scene understanding, tracking, and mapping, achieving 10× faster semantic rendering and 2× lower storage costs compared to existing methods.</p>
        </div>
      </div>
    </div>
  </section>
  <br>

    <!-- Overview -->
    <section>
      <div class="container">
        <div class="row">
          <div class="col-12 text-center">
              <h3>Overview</h3>
              <hr style="margin-top:0px">
              <img class="img-fluid" src="image/my_overview.png">
              <!-- <br><br> -->
              <p class="text-justify">An overview of OpenGS-SLAM. Our method takes an RGB-D stream as input. RGB images are first fed into our Semantic Information Generator to obtain the input label map, along with the confidence scores and corresponding class for each label. Concurrently, G-ICP is used to estimate the camera pose and extract source Gaussian data. Using the current pose, we render an RGB-D image, label map, and contribution record matrix via Gaussian Voting Splatting. Confidence-based 2D Label Consensus is then applied to unify the input label map with the current map, ensuring semantic consistency. During this process, partial Gaussian data is updated, and counter Gaussians are pruned. The consistent input label map and source Gaussians are combined to generate new Gaussian data, achieving scene densification.</p>
              <!--<div class="embed-responsive embed-responsive-16by9">-->
                  <!-- <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/jUkfatSaJtA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
                  <!--<iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/y8XP9Umt6Mw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>-->
          </div>
        </div>
      </div>
    </section>
    <br>

    
  <!-- Videos -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Video</h3>
          <hr style="margin-top:0px">
          <div class="video-container d-flex justify-content-center align-items-center" style="width: 100%; height: 100%;">
            <iframe width="1120" height="630" src="https://www.youtube.com/embed/uNJ4vTpfGU0?si=RWEVSJpeXgawFhP0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>
  <br>


  <!-- citing -->
<!--   <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@misc{gao2024mcnerf,
      title={MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image Acquisition Systems}, 
      author={Yu Gao and Lutong Su and Hao Liang and Yufeng Yue and Yi Yang and Mengyin Fu},
      year={2024},
      eprint={2309.07846},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</code></pre>
          <hr>
      </div>
    </div>
  </div> -->


    <!-- citing -->
  <!-- <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
  <code>@misc{gao2024mcnerf,
        title={MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image Acquisition Systems}, 
        author={Yu Gao and Lutong Su and Hao Liang and Yufeng Yue and Yi Yang and Mengyin Fu},
        year={2024},
        eprint={2309.07846},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
  }</code></pre>
          <hr>
      </div>
    </div>
  </div> -->

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
